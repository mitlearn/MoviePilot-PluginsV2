# -*- coding: utf-8 -*-
"""
JackettIndexer Plugin for MoviePilot

This plugin integrates Jackett indexer search functionality into MoviePilot.
It allows searching across all indexers configured in Jackett through a unified interface.

Version: 0.1.0
Author: Claude
"""

import copy
import re
import traceback
import xml.dom.minidom
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime
from urllib.parse import urlencode

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

from app.core.context import TorrentInfo
from app.helper.sites import SitesHelper
from app.log import logger
from app.plugins import _PluginBase
from app.schemas.types import MediaType
from app.utils.dom import DomUtils
from app.utils.http import RequestUtils


class JackettIndexer(_PluginBase):
    """
    Jackett Indexer Plugin

    Provides torrent search functionality through Jackett Torznab API.
    Registers all configured Jackett indexers as MoviePilot sites.
    """

    # Plugin metadata
    plugin_name = "Jackettç´¢å¼•å™¨"
    plugin_desc = "é›†æˆJackettç´¢å¼•å™¨æœç´¢ï¼Œæ”¯æŒTorznabåè®®å¤šç«™ç‚¹æœç´¢ã€‚"
    plugin_icon = "Jackett_A.png"
    plugin_version = "0.2.4"
    plugin_author = "Claude"
    author_url = "https://github.com"
    plugin_config_prefix = "jackettindexer_"
    plugin_order = 11
    auth_level = 1

    # Private attributes
    _enabled: bool = False
    _host: str = ""
    _api_key: str = ""
    _proxy: bool = False
    _cron: str = "0 0 */6 * *"  # Sync indexers every 6 hours
    _onlyonce: bool = False
    _indexers: List[Dict[str, Any]] = []
    _scheduler: Optional[BackgroundScheduler] = None
    _sites_helper: Optional[SitesHelper] = None
    _last_update: Optional[datetime] = None

    # Domain prefix for indexer identification (using underscore like reference implementation)
    DOMAIN_PREFIX = "jackett_indexer"

    # Torznab namespace for XML parsing
    TORZNAB_NS = "http://torznab.com/schemas/2015/feed"

    def init_plugin(self, config: dict = None):
        """
        Initialize the plugin with user configuration.

        Args:
            config: Configuration dictionary from user settings
        """
        logger.info(f"ã€{self.plugin_name}ã€‘â˜…â˜…â˜… å¼€å§‹åˆå§‹åŒ–æ’ä»¶ â˜…â˜…â˜…")
        logger.debug(f"ã€{self.plugin_name}ã€‘æ”¶åˆ°é…ç½®ï¼š{config}")

        # Stop existing services
        self.stop_service()

        # Load configuration
        if config:
            self._enabled = config.get("enabled", False)
            self._host = config.get("host", "").rstrip("/")
            self._api_key = config.get("api_key", "")
            self._proxy = config.get("proxy", False)
            self._cron = config.get("cron", "0 0 */6 * *")
            self._onlyonce = config.get("onlyonce", False)

        # Validate configuration
        if not self._enabled:
            logger.info(f"ã€{self.plugin_name}ã€‘æ’ä»¶æœªå¯ç”¨")
            return

        if not self._host or not self._api_key:
            logger.error(f"ã€{self.plugin_name}ã€‘é…ç½®é”™è¯¯ï¼šç¼ºå°‘æœåŠ¡å™¨åœ°å€æˆ–APIå¯†é’¥")
            return

        # Validate host format
        if not self._host.startswith(("http://", "https://")):
            logger.error(f"ã€{self.plugin_name}ã€‘é…ç½®é”™è¯¯ï¼šæœåŠ¡å™¨åœ°å€å¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´")
            return

        # Initialize sites helper
        self._sites_helper = SitesHelper()

        # Setup scheduler for periodic sync
        if self._cron:
            try:
                self._scheduler = BackgroundScheduler(timezone="Asia/Shanghai")
                self._scheduler.add_job(
                    func=self._sync_indexers,
                    trigger=CronTrigger.from_crontab(self._cron),
                    name=f"{self.plugin_name}å®šæ—¶åŒæ­¥"
                )
                self._scheduler.start()
                logger.info(f"ã€{self.plugin_name}ã€‘å®šæ—¶åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨ï¼Œå‘¨æœŸï¼š{self._cron}")
            except Exception as e:
                logger.error(f"ã€{self.plugin_name}ã€‘å®šæ—¶ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼š{str(e)}")

        # Handle run once flag
        if self._onlyonce:
            self._onlyonce = False
            self.update_config({
                **config,
                "onlyonce": False
            })
            logger.info(f"ã€{self.plugin_name}ã€‘ç«‹å³è¿è¡Œå®Œæˆï¼Œå·²å…³é—­ç«‹å³è¿è¡Œæ ‡å¿—")

        # Fetch and register indexers
        if not self._indexers:
            logger.info(f"ã€{self.plugin_name}ã€‘å¼€å§‹è·å–ç´¢å¼•å™¨...")
            self._fetch_and_build_indexers()

        # Register indexers to site management (delete and re-add to ensure latest config)
        registered_count = 0
        updated_count = 0
        for indexer in self._indexers:
            domain = indexer.get("domain", "")
            site_info = self._sites_helper.get_indexer(domain)
            new_indexer = copy.deepcopy(indexer)

            if site_info:
                # Site exists, delete and re-add to ensure latest fields
                try:
                    self._sites_helper.delete_indexer(domain)
                    self._sites_helper.add_indexer(domain, new_indexer)
                    logger.info(f"ã€{self.plugin_name}ã€‘ğŸ”„ æ›´æ–°ç«™ç‚¹ç®¡ç†ï¼š{indexer.get('name')} (domain: {domain})")
                    updated_count += 1
                except Exception as e:
                    logger.error(f"ã€{self.plugin_name}ã€‘æ›´æ–°ç«™ç‚¹å¤±è´¥ï¼š{indexer.get('name')}, é”™è¯¯ï¼š{str(e)}")
            else:
                # New site, add it
                self._sites_helper.add_indexer(domain, new_indexer)
                logger.info(f"ã€{self.plugin_name}ã€‘âœ… æ–°å¢åˆ°ç«™ç‚¹ç®¡ç†ï¼š{indexer.get('name')} (domain: {domain})")
                registered_count += 1

        logger.info(f"ã€{self.plugin_name}ã€‘æ’ä»¶åˆå§‹åŒ–å®Œæˆï¼Œæ€»è®¡ {len(self._indexers)} ä¸ªç´¢å¼•å™¨ï¼Œæ–°å¢ {registered_count} ä¸ªï¼Œæ›´æ–° {updated_count} ä¸ª")

    def _fetch_and_build_indexers(self) -> bool:
        """
        Fetch indexers from Jackett and build indexer dictionaries.

        Returns:
            True if successful, False otherwise
        """
        try:
            indexers = self._get_indexers_from_jackett()
            if not indexers:
                logger.warning(f"ã€{self.plugin_name}ã€‘æœªè·å–åˆ°ç´¢å¼•å™¨åˆ—è¡¨")
                return False

            # Build indexer dicts
            self._indexers = []
            for indexer_data in indexers:
                try:
                    indexer_dict = self._build_indexer_dict(indexer_data)
                    self._indexers.append(indexer_dict)
                except Exception as e:
                    logger.error(f"ã€{self.plugin_name}ã€‘æ„å»ºç´¢å¼•å™¨å¤±è´¥ï¼š{str(e)}")
                    continue

            logger.info(f"ã€{self.plugin_name}ã€‘æˆåŠŸè·å– {len(self._indexers)} ä¸ªç´¢å¼•å™¨")
            return True

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘è·å–ç´¢å¼•å™¨å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return False

    def _sync_indexers(self) -> bool:
        """
        Periodic sync: fetch indexers and register new ones.

        Returns:
            True if sync successful, False otherwise
        """
        try:
            # Fetch indexers from Jackett
            if not self._fetch_and_build_indexers():
                return False

            # Register indexers to site management
            registered_count = 0
            for indexer in self._indexers:
                domain = indexer.get("domain", "")
                site_info = self._sites_helper.get_indexer(domain)
                if not site_info:
                    new_indexer = copy.deepcopy(indexer)
                    self._sites_helper.add_indexer(domain, new_indexer)
                    logger.info(f"ã€{self.plugin_name}ã€‘âœ… æˆåŠŸæ·»åŠ åˆ°ç«™ç‚¹ç®¡ç†ï¼š{indexer.get('name')} (domain: {domain})")
                    registered_count += 1

            self._last_update = datetime.now()
            logger.info(f"ã€{self.plugin_name}ã€‘ç´¢å¼•å™¨åŒæ­¥å®Œæˆï¼Œæ€»è®¡ {len(self._indexers)} ä¸ªï¼Œæ–°å¢ {registered_count} ä¸ª")
            return True

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘åŒæ­¥ç´¢å¼•å™¨å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return False

    def _get_indexers_from_jackett(self) -> List[Dict[str, Any]]:
        """
        Fetch indexer list from Jackett API.

        Returns:
            List of indexer dictionaries from Jackett API
        """
        try:
            url = f"{self._host}/api/v2.0/indexers/all/results/torznab/api"
            params = {
                "apikey": self._api_key,
                "t": "indexers",
                "configured": "true"
            }

            logger.debug(f"ã€{self.plugin_name}ã€‘æ­£åœ¨è·å–ç´¢å¼•å™¨åˆ—è¡¨ï¼š{url}")

            response = RequestUtils(proxies=self._proxy).get_res(
                url=url,
                params=params,
                timeout=30
            )

            if not response:
                logger.error(f"ã€{self.plugin_name}ã€‘APIè¯·æ±‚å¤±è´¥ï¼šæ— å“åº”")
                return []

            if response.status_code != 200:
                logger.error(f"ã€{self.plugin_name}ã€‘APIè¯·æ±‚å¤±è´¥ï¼šHTTP {response.status_code}")
                logger.debug(f"ã€{self.plugin_name}ã€‘å“åº”å†…å®¹ï¼š{response.text}")
                return []

            # Parse XML response
            indexers = self._parse_indexers_xml(response.text)

            logger.info(f"ã€{self.plugin_name}ã€‘è·å–åˆ° {len(indexers)} ä¸ªç´¢å¼•å™¨")

            return indexers

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘è·å–ç´¢å¼•å™¨åˆ—è¡¨å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return []

    def _parse_indexers_xml(self, xml_content: str) -> List[Dict[str, Any]]:
        """
        Parse Jackett indexers XML response.

        Args:
            xml_content: XML response string

        Returns:
            List of indexer dictionaries
        """
        try:
            # Parse XML
            dom_tree = xml.dom.minidom.parseString(xml_content)
            root_node = dom_tree.documentElement

            # Check for error response
            if root_node.tagName == "error":
                error_code = root_node.getAttribute("code")
                error_desc = root_node.getAttribute("description")
                logger.error(f"ã€{self.plugin_name}ã€‘Torznabé”™è¯¯ {error_code}ï¼š{error_desc}")
                return []

            # Find indexer elements
            indexer_elements = root_node.getElementsByTagName("indexer")

            indexers = []
            for elem in indexer_elements:
                try:
                    indexer = {
                        "id": elem.getAttribute("id"),
                        "title": DomUtils.tag_value(elem, "title", default=""),
                        "type": elem.getAttribute("type"),
                        "language": elem.getAttribute("language") or "en-US",
                    }

                    # Only add if we have required fields
                    if indexer["id"] and indexer["title"]:
                        indexers.append(indexer)
                        logger.debug(f"ã€{self.plugin_name}ã€‘è§£æåˆ°ç´¢å¼•å™¨ï¼šid={indexer['id']}, title={indexer['title']}")

                except Exception as e:
                    logger.debug(f"ã€{self.plugin_name}ã€‘è§£æç´¢å¼•å™¨å¤±è´¥ï¼š{str(e)}")
                    continue

            return indexers

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘è§£æXMLå¤±è´¥ï¼š{str(e)}")
            return []

    def _build_indexer_dict(self, indexer: Dict[str, Any]) -> Dict[str, Any]:
        """
        Build MoviePilot indexer dictionary from Jackett indexer data.

        Args:
            indexer: Jackett indexer dictionary

        Returns:
            MoviePilot compatible indexer dictionary
        """
        indexer_id = indexer.get("id", "")
        indexer_title = indexer.get("title", f"Indexer-{indexer_id}")

        # Build domain identifier (matching reference implementation pattern)
        # Format: jackett_indexer.{indexer_id}
        domain = f"{self.DOMAIN_PREFIX}.{indexer_id}"

        # Build simplified indexer dictionary (matching reference implementation)
        # Only include fields that are in the reference implementation
        # Note: url should be the main Jackett host, not the API endpoint
        # This URL is used by MoviePilot for displaying site info, not for searching
        return {
            "id": f"{self.plugin_name}-{indexer_title}",
            "name": f"{self.plugin_name}-{indexer_title}",
            "url": self._host,  # Use Jackett host as the site URL
            "domain": domain,
            "public": True,
            "proxy": self._proxy,
            "render": False,  # Don't use built-in rendering/parsing
            "builtin": False,  # Mark as non-builtin indexer
            "pri": 10,  # Priority
        }

    def get_state(self) -> bool:
        """
        Get plugin enabled state.

        Returns:
            True if plugin is enabled, False otherwise
        """
        return self._enabled

    def stop_service(self):
        """
        Stop plugin services and cleanup resources.
        """
        try:
            # Stop scheduler
            if self._scheduler:
                try:
                    self._scheduler.remove_all_jobs()
                    if self._scheduler.running:
                        self._scheduler.shutdown(wait=False)
                    self._scheduler = None
                    logger.info(f"ã€{self.plugin_name}ã€‘å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"ã€{self.plugin_name}ã€‘åœæ­¢å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼š{str(e)}")

            # Note: We intentionally do NOT unregister indexers from site management
            # This allows sites to persist between plugin restarts and MoviePilot reboots
            # If you need to remove sites, disable them manually in the site management UI
            if self._indexers:
                logger.info(f"ã€{self.plugin_name}ã€‘æœåŠ¡å·²åœæ­¢ï¼Œ{len(self._indexers)} ä¸ªç´¢å¼•å™¨ä¿ç•™åœ¨ç«™ç‚¹ç®¡ç†ä¸­")
                self._indexers = []

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘åœæ­¢æœåŠ¡å¼‚å¸¸ï¼š{str(e)}")

    def get_module(self) -> Dict[str, Any]:
        """
        Declare module methods to hijack system search.

        Returns:
            Dictionary mapping method names to plugin methods
        """
        if not self._enabled:
            logger.debug(f"ã€{self.plugin_name}ã€‘get_module è¢«è°ƒç”¨ï¼Œä½†æ’ä»¶æœªå¯ç”¨ï¼Œè¿”å›ç©ºå­—å…¸")
            return {}

        result = {
            "search_torrents": self.search_torrents,
        }
        logger.info(f"ã€{self.plugin_name}ã€‘get_module è¢«è°ƒç”¨ï¼Œæ³¨å†Œ search_torrents æ–¹æ³•")
        logger.info(f"ã€{self.plugin_name}ã€‘è¿”å›æ–¹æ³•å¯¹è±¡ï¼š{result['search_torrents']}")
        logger.info(f"ã€{self.plugin_name}ã€‘æ–¹æ³•æ˜¯å¦å¯è°ƒç”¨ï¼š{callable(result['search_torrents'])}")
        return result

    def search_torrents(
        self,
        site: Dict[str, Any],
        keyword: str,
        mtype: Optional[MediaType] = None,
        page: Optional[int] = 0
    ) -> List[TorrentInfo]:
        """
        Search torrents through Jackett Torznab API.

        This method is called by MoviePilot's module hijacking system.

        Args:
            site: Site/indexer information dictionary
            keyword: Search keyword
            mtype: Media type (MOVIE or TV)
            page: Page number for pagination

        Returns:
            List of TorrentInfo objects
        """
        # CRITICAL: Log IMMEDIATELY at method entry - before ANY code
        import sys
        sys.stderr.write(f"=== JACKETT search_torrents CALLED ===\n")
        sys.stderr.flush()

        results = []

        # First line of the method - log immediately
        logger.info(f"ã€{self.plugin_name}ã€‘â˜…â˜…â˜… search_torrents æ–¹æ³•è¢«è°ƒç”¨ â˜…â˜…â˜…")
        logger.info(f"ã€{self.plugin_name}ã€‘site={site}, keyword={keyword}")

        try:
            # Debug: Log method call with all parameters
            logger.debug(f"ã€{self.plugin_name}ã€‘search_torrents è¢«è°ƒç”¨ï¼Œsite type={type(site)}, keyword={keyword}")

            # Validate inputs first (matching reference implementation pattern)
            if site is None:
                logger.debug(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹å‚æ•°ä¸º Noneï¼Œè¿”å›ç©ºç»“æœ")
                return results

            if not isinstance(site, dict):
                logger.error(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹å‚æ•°ç±»å‹é”™è¯¯ï¼šæœŸæœ› dictï¼Œå¾—åˆ° {type(site)}")
                return results

            if not keyword:
                logger.debug(f"ã€{self.plugin_name}ã€‘å…³é”®è¯ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                return results
        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘å‚æ•°éªŒè¯å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return results

        try:
            # Get site name for logging
            site_name = site.get("name", "Unknown")
            logger.debug(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹åç§°ï¼š{site_name}, plugin_name: {self.plugin_name}")

            # Check if this site belongs to our plugin (matching reference implementation)
            site_name_value = site.get("name", "")
            if not site_name_value:
                logger.debug(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹åç§°ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                return results

            site_prefix = site_name_value.split("-")[0] if "-" in site_name_value else site_name_value
            logger.debug(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹å‰ç¼€ï¼š{site_prefix}, æ˜¯å¦åŒ¹é…ï¼š{site_prefix == self.plugin_name}")

            if site_prefix != self.plugin_name:
                logger.debug(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹ä¸å±äºæœ¬æ’ä»¶ï¼Œè¿”å›ç©ºç»“æœ")
                return results
        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹åç§°å¤„ç†å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return results

        try:
            # Log that method was called
            logger.info(f"ã€{self.plugin_name}ã€‘å¼€å§‹æœç´¢ï¼šç«™ç‚¹={site_name}, å…³é”®è¯={keyword}, ç±»å‹={mtype}, é¡µç ={page}")

            # Extract indexer ID from domain (matching reference implementation)
            # Domain format: jackett_indexer.{indexer_id}
            domain = site.get("domain", "")
            if not domain:
                logger.warning(f"ã€{self.plugin_name}ã€‘ç«™ç‚¹ç¼ºå°‘ domain å­—æ®µï¼š{site_name}")
                return results

            # Parse indexer ID from domain (format: jackett_indexer.indexer-id)
            # Use proper prefix removal instead of split to handle indexer IDs with dots
            if not domain.startswith(f"{self.DOMAIN_PREFIX}."):
                logger.warning(f"ã€{self.plugin_name}ã€‘domainæ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä»¥ {self.DOMAIN_PREFIX}. å¼€å¤´ï¼š{domain}")
                return results

            indexer_id = domain[len(self.DOMAIN_PREFIX) + 1:]  # Remove prefix
            if not indexer_id:
                logger.warning(f"ã€{self.plugin_name}ã€‘ä»domainæå–çš„ç´¢å¼•å™¨IDä¸ºç©ºï¼š{domain}")
                return results

            logger.info(f"ã€{self.plugin_name}ã€‘ä»domainæå–ç´¢å¼•å™¨IDï¼š{indexer_id}ï¼Œå‡†å¤‡æ„å»ºæœç´¢URL")

            # Build search parameters
            search_params = self._build_search_params(
                keyword=keyword,
                mtype=mtype,
                page=page
            )

            # Execute search API call
            xml_content = self._search_jackett_api(indexer_id, search_params)

            if not xml_content:
                logger.debug(f"ã€{self.plugin_name}ã€‘æœç´¢æœªè¿”å›ç»“æœ")
                return results

            # Additional safety check for xml_content type
            if not isinstance(xml_content, str):
                logger.error(f"ã€{self.plugin_name}ã€‘æœç´¢è¿”å›äº†éå­—ç¬¦ä¸²ç±»å‹çš„ç»“æœï¼š{type(xml_content)}")
                return results

            # Parse XML results to TorrentInfo
            results = self._parse_torznab_xml(xml_content, site_name)

            logger.info(f"ã€{self.plugin_name}ã€‘æœç´¢å®Œæˆï¼š{site_name} è¿”å› {len(results)} ä¸ªç»“æœ")

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘æœç´¢å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")

        return results

    def _build_search_params(
        self,
        keyword: str,
        mtype: Optional[MediaType] = None,
        page: int = 0
    ) -> Dict[str, Any]:
        """
        Build Jackett Torznab API search parameters.

        Args:
            keyword: Search keyword
            mtype: Media type for category filtering
            page: Page number

        Returns:
            Dictionary of search parameters
        """
        # Determine categories based on media type
        categories = self._get_categories(mtype)

        # Build parameters
        params = {
            "apikey": self._api_key,
            "t": "search",
            "q": keyword,
            "limit": 100,
            "offset": page * 100 if page else 0,
        }

        # Add categories as comma-separated string
        if categories:
            params["cat"] = ",".join(map(str, categories))

        return params

    @staticmethod
    def _get_categories(mtype: Optional[MediaType] = None) -> List[int]:
        """
        Get Torznab category IDs based on media type.

        Args:
            mtype: Media type (MOVIE, TV, or None for all)

        Returns:
            List of category IDs
        """
        if not mtype:
            return [2000, 5000]  # Both movies and TV
        elif mtype == MediaType.MOVIE:
            return [2000]  # Movies
        elif mtype == MediaType.TV:
            return [5000]  # TV shows
        else:
            return [2000, 5000]

    def _search_jackett_api(self, indexer_id: str, params: Dict[str, Any]) -> Optional[str]:
        """
        Execute Jackett Torznab API search request.

        Args:
            indexer_id: Jackett indexer identifier
            params: Query parameters dictionary

        Returns:
            XML response string or None if failed
        """
        try:
            # Build URL for specific indexer
            url = f"{self._host}/api/v2.0/indexers/{indexer_id}/results/torznab/api"

            logger.info(f"ã€{self.plugin_name}ã€‘APIè¯·æ±‚ï¼š{url}")
            logger.debug(f"ã€{self.plugin_name}ã€‘æœç´¢å‚æ•°ï¼š{params}")

            response = RequestUtils(proxies=self._proxy).get_res(
                url=url,
                params=params,
                timeout=60
            )

            if not response:
                logger.error(f"ã€{self.plugin_name}ã€‘æœç´¢APIè¯·æ±‚å¤±è´¥ï¼šæ— å“åº”")
                return None

            # Check if response has status_code attribute
            if not hasattr(response, 'status_code'):
                logger.error(f"ã€{self.plugin_name}ã€‘å“åº”å¯¹è±¡æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘status_codeå±æ€§")
                return None

            if response.status_code != 200:
                logger.error(f"ã€{self.plugin_name}ã€‘æœç´¢APIè¯·æ±‚å¤±è´¥ï¼šHTTP {response.status_code}")
                # Safely get response text
                response_text = getattr(response, 'text', '')
                if response_text:
                    logger.debug(f"ã€{self.plugin_name}ã€‘å“åº”å†…å®¹ï¼š{response_text[:500]}")
                return None

            # Safely get response text
            xml_content = getattr(response, 'text', None)
            if xml_content is None:
                logger.error(f"ã€{self.plugin_name}ã€‘å“åº”å¯¹è±¡æ²¡æœ‰textå±æ€§")
                return None

            return xml_content

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘æœç´¢APIå¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
            return None

    def _parse_torznab_xml(self, xml_content: str, site_name: str) -> List[TorrentInfo]:
        """
        Parse Torznab XML response to TorrentInfo objects.

        Args:
            xml_content: XML response string
            site_name: Site name for attribution

        Returns:
            List of TorrentInfo objects
        """
        results = []

        try:
            # Validate xml_content
            if not xml_content or not isinstance(xml_content, str):
                logger.error(f"ã€{self.plugin_name}ã€‘XMLå†…å®¹ä¸ºç©ºæˆ–ç±»å‹é”™è¯¯")
                return results

            # Parse XML
            dom_tree = xml.dom.minidom.parseString(xml_content)
            root_node = dom_tree.documentElement

            # Safety check for root_node
            if not root_node:
                logger.error(f"ã€{self.plugin_name}ã€‘XMLè§£æå¤±è´¥ï¼šæ— æ³•è·å–æ ¹èŠ‚ç‚¹")
                return results

            # Check for error response
            if root_node.tagName == "error":
                error_code = root_node.getAttribute("code")
                error_desc = root_node.getAttribute("description")
                logger.error(f"ã€{self.plugin_name}ã€‘Torznabé”™è¯¯ {error_code}ï¼š{error_desc}")
                return []

            # Find channel and items
            channel = root_node.getElementsByTagName("channel")
            if not channel:
                logger.debug(f"ã€{self.plugin_name}ã€‘XMLå“åº”ä¸­æœªæ‰¾åˆ° channel å…ƒç´ ")
                return []

            items = channel[0].getElementsByTagName("item")

            for item in items:
                try:
                    torrent_info = self._parse_torznab_item(item, site_name)
                    if torrent_info:
                        results.append(torrent_info)
                except Exception as e:
                    logger.debug(f"ã€{self.plugin_name}ã€‘è§£æitemå¤±è´¥ï¼š{str(e)}")
                    continue

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘è§£æXMLå¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")

        return results

    def _parse_torznab_item(self, item, site_name: str) -> Optional[TorrentInfo]:
        """
        Parse single Torznab item element to TorrentInfo.

        Args:
            item: XML item element
            site_name: Site name for attribution

        Returns:
            TorrentInfo object or None if parsing fails
        """
        try:
            # Extract basic fields
            title = DomUtils.tag_value(item, "title", default="")
            if not title:
                return None

            # Get download link
            enclosure_node = item.getElementsByTagName("enclosure")
            if enclosure_node:
                enclosure = enclosure_node[0].getAttribute("url")
            else:
                enclosure = DomUtils.tag_value(item, "link", default="")

            # Try to get magnet link from torznab attributes
            magnet_url = self._get_torznab_attr(item, "magneturl")
            if magnet_url:
                enclosure = magnet_url

            if not enclosure:
                logger.debug(f"ã€{self.plugin_name}ã€‘è·³è¿‡æ— ä¸‹è½½é“¾æ¥çš„ç»“æœï¼š{title}")
                return None

            # Get size
            size_str = DomUtils.tag_value(item, "size", default="0")
            try:
                size = int(size_str) if size_str.isdigit() else 0
            except Exception:
                size = 0

            # Get seeders and peers from torznab attributes
            seeders = self._get_torznab_attr_int(item, "seeders", 0)
            peers = self._get_torznab_attr_int(item, "peers", 0)

            # Calculate leechers (peers includes seeders in Torznab)
            leechers = max(0, peers - seeders)

            # Get other fields
            pub_date = DomUtils.tag_value(item, "pubDate", default="")
            description = DomUtils.tag_value(item, "description", default="")
            page_url = DomUtils.tag_value(item, "comments", default="") or \
                      DomUtils.tag_value(item, "guid", default="")

            # Get metadata from torznab attributes
            imdb_id = self._get_torznab_attr(item, "imdbid")
            grabs = self._get_torznab_attr_int(item, "grabs", 0)

            # Determine if freeleech (downloadvolumefactor=0)
            download_factor = self._get_torznab_attr_float(item, "downloadvolumefactor", 1.0)

            # Build TorrentInfo
            torrent = TorrentInfo(
                title=title,
                enclosure=enclosure,
                description=description,
                size=size,
                seeders=seeders,
                peers=leechers,
                page_url=page_url,
                site_name=site_name,
                pubdate=self._parse_rfc2822_date(pub_date),
                imdbid=self._format_imdb_id(imdb_id),
                downloadvolumefactor=download_factor,
                uploadvolumefactor=1.0,
                grabs=grabs,
            )

            return torrent

        except Exception as e:
            logger.error(f"ã€{self.plugin_name}ã€‘è§£æç§å­ä¿¡æ¯å¼‚å¸¸ï¼š{str(e)}")
            return None

    def _get_torznab_attr(self, item, attr_name: str, default: str = "") -> str:
        """
        Get Torznab attribute value from item.

        Args:
            item: XML item element
            attr_name: Attribute name to find
            default: Default value if not found

        Returns:
            Attribute value as string
        """
        try:
            attrs = item.getElementsByTagName("torznab:attr")
            for attr in attrs:
                if attr.getAttribute("name") == attr_name:
                    return attr.getAttribute("value")
            return default
        except Exception:
            return default

    def _get_torznab_attr_int(self, item, attr_name: str, default: int = 0) -> int:
        """Get Torznab attribute as integer."""
        try:
            value = self._get_torznab_attr(item, attr_name, str(default))
            return int(value) if value.isdigit() else default
        except Exception:
            return default

    def _get_torznab_attr_float(self, item, attr_name: str, default: float = 0.0) -> float:
        """Get Torznab attribute as float."""
        try:
            value = self._get_torznab_attr(item, attr_name, str(default))
            return float(value)
        except Exception:
            return default

    @staticmethod
    def _parse_rfc2822_date(date_str: str) -> str:
        """
        Parse RFC 2822 date string to MoviePilot format.

        Args:
            date_str: RFC 2822 date string (e.g., "Thu, 15 Jun 2023 12:34:56 +0000")

        Returns:
            Formatted date string (YYYY-MM-DD HH:MM:SS)
        """
        try:
            if not date_str:
                return ""

            # Try to parse RFC 2822 format
            from email.utils import parsedate_to_datetime
            dt = parsedate_to_datetime(date_str)

            # Format to MoviePilot standard
            return dt.strftime("%Y-%m-%d %H:%M:%S")

        except Exception:
            return date_str  # Return original if parsing fails

    @staticmethod
    def _format_imdb_id(imdb_id: Any) -> str:
        """
        Format IMDB ID to standard tt prefix format.

        Args:
            imdb_id: IMDB ID (integer or string)

        Returns:
            Formatted IMDB ID string (e.g., "tt0137523")
        """
        try:
            if not imdb_id:
                return ""

            # Convert to string
            imdb_str = str(imdb_id)

            # Add tt prefix if missing
            if not imdb_str.startswith("tt"):
                imdb_str = f"tt{imdb_str}"

            return imdb_str

        except Exception:
            return ""

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        """
        Get plugin configuration form for web UI.

        Returns:
            Tuple of (form_elements, default_config)
        """
        return [
            {
                'component': 'VForm',
                'content': [
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'enabled',
                                            'label': 'å¯ç”¨æ’ä»¶',
                                            'hint': 'å¼€å¯åå°†ä½¿ç”¨Jackettè¿›è¡Œæœç´¢',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'onlyonce',
                                            'label': 'ç«‹å³è¿è¡Œä¸€æ¬¡',
                                            'hint': 'æ’ä»¶å°†ç«‹å³åŒæ­¥ç´¢å¼•å™¨åˆ—è¡¨',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'host',
                                            'label': 'æœåŠ¡å™¨åœ°å€',
                                            'placeholder': 'http://127.0.0.1:9117',
                                            'hint': 'JackettæœåŠ¡å™¨åœ°å€ï¼Œå¦‚ï¼šhttp://127.0.0.1:9117',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'api_key',
                                            'label': 'APIå¯†é’¥',
                                            'placeholder': '',
                                            'hint': 'åœ¨Jackettç•Œé¢ç‚¹å‡»æ‰³æ‰‹å›¾æ ‡è·å–APIå¯†é’¥',
                                            'persistent-hint': True,
                                            'type': 'password'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'cron',
                                            'label': 'åŒæ­¥å‘¨æœŸ',
                                            'placeholder': '0 0 */6 * *',
                                            'hint': 'Cronè¡¨è¾¾å¼ï¼Œé»˜è®¤æ¯6å°æ—¶åŒæ­¥ä¸€æ¬¡ç´¢å¼•å™¨',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'proxy',
                                            'label': 'ä½¿ç”¨ä»£ç†',
                                            'hint': 'è®¿é—®Jackettæ—¶ä½¿ç”¨ç³»ç»Ÿä»£ç†',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12},
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'æ’ä»¶å°†è‡ªåŠ¨åŒæ­¥Jackettä¸­å·²é…ç½®çš„ç´¢å¼•å™¨ï¼Œæ¯ä¸ªç´¢å¼•å™¨å°†æ³¨å†Œä¸ºä¸€ä¸ªç«™ç‚¹ã€‚æœç´¢æ—¶å°†é€šè¿‡Jackett Torznab APIè¿›è¡ŒæŸ¥è¯¢ã€‚'
                                        }
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ], {
            "enabled": False,
            "host": "",
            "api_key": "",
            "proxy": False,
            "cron": "0 0 */6 * *",
            "onlyonce": False
        }

    def get_page(self) -> List[dict]:
        """
        æ‹¼è£…æ’ä»¶è¯¦æƒ…é¡µé¢ï¼Œéœ€è¦è¿”å›é¡µé¢é…ç½®ï¼ŒåŒæ—¶é™„å¸¦æ•°æ®
        """
        # Build status info
        status_info = []
        if self._enabled:
            status_info.append('çŠ¶æ€ï¼šè¿è¡Œä¸­')
        else:
            status_info.append('çŠ¶æ€ï¼šå·²åœç”¨')

        if self._last_update:
            status_info.append(f'æœ€ååŒæ­¥ï¼š{self._last_update.strftime("%Y-%m-%d %H:%M:%S")}')

        status_info.append(f'ç´¢å¼•å™¨æ•°é‡ï¼š{len(self._indexers)}')

        # Build table rows
        items = []
        if self._indexers:
            for site in self._indexers:
                items.append({
                    'component': 'tr',
                    'content': [
                        {
                            'component': 'td',
                            'text': site.get("name", "Unknown")
                        },
                        {
                            'component': 'td',
                            'text': site.get("domain", "N/A")
                        },
                        {
                            'component': 'td',
                            'text': 'æ˜¯' if site.get("public", False) else 'å¦'
                        }
                    ]
                })

        # Build page elements
        return [
            {
                'component': 'VRow',
                'content': [
                    {
                        'component': 'VCol',
                        'props': {'cols': 12},
                        'content': [
                            {
                                'component': 'VAlert',
                                'props': {
                                    'type': 'success' if self._enabled else 'info',
                                    'variant': 'tonal',
                                    'text': ' | '.join(status_info)
                                }
                            }
                        ]
                    }
                ]
            },
            {
                'component': 'VRow',
                'content': [
                    {
                        'component': 'VCol',
                        'props': {
                            'cols': 12
                        },
                        'content': [
                            {
                                'component': 'VTable',
                                'props': {
                                    'hover': True
                                },
                                'content': [
                                    {
                                        'component': 'thead',
                                        'content': [
                                            {
                                                'component': 'tr',
                                                'content': [
                                                    {
                                                        'component': 'th',
                                                        'props': {
                                                            'class': 'text-start ps-4'
                                                        },
                                                        'text': 'ç´¢å¼•å™¨åç§°'
                                                    },
                                                    {
                                                        'component': 'th',
                                                        'props': {
                                                            'class': 'text-start ps-4'
                                                        },
                                                        'text': 'ç«™ç‚¹domain'
                                                    },
                                                    {
                                                        'component': 'th',
                                                        'props': {
                                                            'class': 'text-start ps-4'
                                                        },
                                                        'text': 'å…¬å¼€ç«™ç‚¹ï¼Ÿ'
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        'component': 'tbody',
                                        'content': items
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ]

    def get_indexers(self) -> List[Dict[str, Any]]:
        """
        è¿”å›æ’ä»¶ç®¡ç†çš„ç´¢å¼•å™¨åˆ—è¡¨ï¼Œä¾›ç³»ç»ŸæŸ¥è¯¢

        Returns:
            List of indexer dictionaries
        """
        return self._indexers if self._indexers else []

    def get_api(self) -> List[Dict[str, Any]]:
        """
        Get plugin API endpoints.

        Returns:
            List of API endpoint definitions
        """
        # æä¾› API ç«¯ç‚¹è¿”å›ç´¢å¼•å™¨åˆ—è¡¨
        return [
            {
                "path": "/indexers",
                "endpoint": self.get_indexers,
                "methods": ["GET"],
                "summary": "è·å–ç´¢å¼•å™¨åˆ—è¡¨",
                "description": "è¿”å›æ‰€æœ‰å·²æ³¨å†Œçš„ Jackett ç´¢å¼•å™¨"
            }
        ]
